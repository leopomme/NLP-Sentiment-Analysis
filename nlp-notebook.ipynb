{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-17T20:34:49.671073Z","iopub.status.busy":"2023-04-17T20:34:49.670146Z","iopub.status.idle":"2023-04-17T20:34:51.378192Z","shell.execute_reply":"2023-04-17T20:34:51.376927Z","shell.execute_reply.started":"2023-04-17T20:34:49.671033Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'NLP-Sentiment-Analysis'...\n","remote: Enumerating objects: 26, done.\u001b[K\n","remote: Counting objects: 100% (26/26), done.\u001b[K\n","remote: Compressing objects: 100% (21/21), done.\u001b[K\n","remote: Total 26 (delta 4), reused 19 (delta 3), pack-reused 0\u001b[K\n","Receiving objects: 100% (26/26), 83.37 KiB | 2.98 MiB/s, done.\n","Resolving deltas: 100% (4/4), done.\n"]}],"source":["!git clone -b leo-1 --single-branch https://github.com/leopomme/NLP-Sentiment-Analysis"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-17T20:34:51.381306Z","iopub.status.busy":"2023-04-17T20:34:51.380918Z","iopub.status.idle":"2023-04-17T20:34:57.024346Z","shell.execute_reply":"2023-04-17T20:34:57.023363Z","shell.execute_reply.started":"2023-04-17T20:34:51.381263Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a245cb5a547e4fdcb9950cf97ac85b08","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07b5a12db0f64955b5d4bca293f2a4e8","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"039f5a48fbbf4053bb0e5f460dde264e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f87307620fbb4f8faa8e96210b2a8d05","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from typing import List\n","\n","import torch\n","import itertools\n","from typing import Dict, List, Optional\n","import pandas as pd\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","from sklearn.preprocessing import LabelEncoder\n","import torch.optim as optim\n","from sklearn.metrics import accuracy_score\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  # other pre-trained models like 'roberta-base'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-17T20:34:57.027463Z","iopub.status.busy":"2023-04-17T20:34:57.026492Z","iopub.status.idle":"2023-04-17T20:34:57.032616Z","shell.execute_reply":"2023-04-17T20:34:57.031301Z","shell.execute_reply.started":"2023-04-17T20:34:57.027421Z"},"trusted":true},"outputs":[],"source":["import os\n","os.chdir('/kaggle/working/NLP-Sentiment-Analysis/src/')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-17T20:42:08.045234Z","iopub.status.busy":"2023-04-17T20:42:08.044703Z","iopub.status.idle":"2023-04-17T21:08:37.782145Z","shell.execute_reply":"2023-04-17T21:08:37.780550Z","shell.execute_reply.started":"2023-04-17T20:42:08.045187Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 1\n","  1.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.6997, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.4142, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3102, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2511, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2099, Dev Accuracy: 0.8324\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.1813, Dev Accuracy: 0.8165\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1572, Dev Accuracy: 0.8245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1325, Dev Accuracy: 0.8059\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1330, Dev Accuracy: 0.8085\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1144, Dev Accuracy: 0.7979\n","\n","  1.2. Eval on the dev set... Acc.: 79.79\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 2\n","  2.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.6413, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.3991, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3242, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2747, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2354, Dev Accuracy: 0.8431\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.2003, Dev Accuracy: 0.8431\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1801, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1588, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1433, Dev Accuracy: 0.8245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1214, Dev Accuracy: 0.8165\n","\n","  2.2. Eval on the dev set... Acc.: 81.65\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 3\n","  3.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.6640, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.3883, Dev Accuracy: 0.8457\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3018, Dev Accuracy: 0.8032\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2488, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2029, Dev Accuracy: 0.8511\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.1751, Dev Accuracy: 0.8457\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1527, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1338, Dev Accuracy: 0.8404\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1242, Dev Accuracy: 0.8245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1115, Dev Accuracy: 0.8298\n","\n","  3.2. Eval on the dev set... Acc.: 82.98\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 4\n","  4.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.6295, Dev Accuracy: 0.8404\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.3899, Dev Accuracy: 0.8191\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3338, Dev Accuracy: 0.8191\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2750, Dev Accuracy: 0.8324\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2446, Dev Accuracy: 0.8484\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.2244, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.2079, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1841, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1808, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1571, Dev Accuracy: 0.8378\n","\n","  4.2. Eval on the dev set... Acc.: 83.78\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 5\n","  5.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.7200, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.4051, Dev Accuracy: 0.8032\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3105, Dev Accuracy: 0.8165\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2732, Dev Accuracy: 0.8324\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2225, Dev Accuracy: 0.8431\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.2024, Dev Accuracy: 0.8457\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1705, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1545, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1374, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1294, Dev Accuracy: 0.8112\n","\n","  5.2. Eval on the dev set... Acc.: 81.12\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 6\n","  6.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.6918, Dev Accuracy: 0.8032\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.4084, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3229, Dev Accuracy: 0.8165\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2630, Dev Accuracy: 0.8245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2351, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.2105, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1894, Dev Accuracy: 0.8404\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1667, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1430, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1391, Dev Accuracy: 0.8218\n","\n","  6.2. Eval on the dev set... Acc.: 82.18\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 7\n","  7.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.7031, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.3933, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3064, Dev Accuracy: 0.8404\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2506, Dev Accuracy: 0.8324\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2047, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.1685, Dev Accuracy: 0.8324\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1417, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1255, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1210, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1091, Dev Accuracy: 0.8271\n","\n","  7.2. Eval on the dev set... Acc.: 82.71\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 8\n","  8.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.6843, Dev Accuracy: 0.8324\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.3937, Dev Accuracy: 0.8245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.2881, Dev Accuracy: 0.8059\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2241, Dev Accuracy: 0.8218\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.1870, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.1542, Dev Accuracy: 0.8218\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1409, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1330, Dev Accuracy: 0.8165\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1277, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1181, Dev Accuracy: 0.8112\n","\n","  8.2. Eval on the dev set... Acc.: 81.12\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 9\n","  9.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.6819, Dev Accuracy: 0.8511\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.3974, Dev Accuracy: 0.8191\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3211, Dev Accuracy: 0.8218\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2706, Dev Accuracy: 0.8112\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2409, Dev Accuracy: 0.8245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.2186, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1896, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1727, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1538, Dev Accuracy: 0.8324\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1419, Dev Accuracy: 0.8191\n","\n","  9.2. Eval on the dev set... Acc.: 81.91\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","RUN: 10\n","  10.1. Training the classifier...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,Loss: 0.6883, Dev Accuracy: 0.8431\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2,Loss: 0.3877, Dev Accuracy: 0.8271\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3,Loss: 0.3155, Dev Accuracy: 0.8112\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4,Loss: 0.2728, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5,Loss: 0.2384, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6,Loss: 0.2141, Dev Accuracy: 0.8351\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7,Loss: 0.1978, Dev Accuracy: 0.8378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8,Loss: 0.1749, Dev Accuracy: 0.8245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9,Loss: 0.1738, Dev Accuracy: 0.8298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 94/94 [00:14<00:00,  6.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10,Loss: 0.1546, Dev Accuracy: 0.8271\n","\n","  10.2. Eval on the dev set... Acc.: 82.71\n","\n","\n","Completed 10 runs.\n","Dev accs: [79.79, 81.65, 82.98, 83.78, 81.12, 82.18, 82.71, 81.12, 81.91, 82.71]\n","Test accs: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n","\n","Mean Dev Acc.: 81.99 (1.08)\n","Mean Test Acc.: -1.00 (0.00)\n","\n","Exec time: 1589.72 s. ( 158 per run )\n"]}],"source":["import time, sys\n","import numpy as np\n","import argparse\n","\n","import torch\n","\n","from classifier import Classifier\n","\n","\n","def set_reproducible():\n","    # The below is necessary to have reproducible behavior.\n","    import random as rn\n","    import os\n","    os.environ['PYTHONHASHSEED'] = '0'\n","    # The below is necessary for starting Numpy generated random numbers\n","    # in a well-defined initial state.\n","    np.random.seed(17)\n","    # The below is necessary for starting core Python generated random numbers\n","    # in a well-defined state.\n","    rn.seed(12345)\n","\n","\n","\n","def load_label_output(filename):\n","    with open(filename, 'r', encoding='UTF-8') as f:\n","        return [line.strip().split(\"\\t\")[0] for line in f if line.strip()]\n","\n","\n","\n","def eval_list(glabels, slabels):\n","    if (len(glabels) != len(slabels)):\n","        print(\"\\nWARNING: label count in system output (%d) is different from gold label count (%d)\\n\" % (\n","        len(slabels), len(glabels)))\n","    n = min(len(slabels), len(glabels))\n","    incorrect_count = 0\n","    for i in range(n):\n","        if slabels[i] != glabels[i]: incorrect_count += 1\n","    acc = (n - incorrect_count) / n\n","    return acc*100\n","\n","\n","\n","def train_and_eval(classifier, trainfile, devfile, testfile, run_id, device):\n","    print(f\"\\nRUN: {run_id}\")\n","    print(\"  %s.1. Training the classifier...\" % str(run_id))\n","    classifier.train(trainfile, devfile, device)\n","    print()\n","    print(\"  %s.2. Eval on the dev set...\" % str(run_id), end=\"\")\n","    slabels = classifier.predict(devfile, device)\n","    glabels = load_label_output(devfile)\n","    devacc = eval_list(glabels, slabels)\n","    print(\" Acc.: %.2f\" % devacc)\n","    testacc = -1\n","    if testfile is not None:\n","        # Evaluation on the test data\n","        print(\"  %s.3. Eval on the test set...\" % str(run_id), end=\"\")\n","        slabels = classifier.predict(testfile)\n","        glabels = load_label_output(testfile)\n","        testacc = eval_list(glabels, slabels)\n","        print(\" Acc.: %.2f\" % testacc)\n","    print()\n","    return (devacc, testacc)\n","\n","\n","if __name__ == \"__main__\":\n","    device_name = \"cuda\"\n","    device = torch.device(device_name)\n","    n_runs = 10\n","    set_reproducible()\n","    datadir = \"../data/\"\n","    trainfile =  datadir + \"traindata.csv\"\n","    devfile =  datadir + \"devdata.csv\"\n","    testfile = None\n","    # testfile = datadir + \"testdata.csv\"\n","\n","    # Runs\n","    start_time = time.perf_counter()\n","    devaccs = []\n","    testaccs = []\n","    for i in range(1, n_runs+1):\n","        classifier =  Classifier()\n","        devacc, testacc = train_and_eval(classifier, trainfile, devfile, testfile, i, device)\n","        devaccs.append(np.round(devacc,2))\n","        testaccs.append(np.round(testacc,2))\n","    print('\\nCompleted %d runs.' % n_runs)\n","    total_exec_time = (time.perf_counter() - start_time)\n","    print(\"Dev accs:\", devaccs)\n","    print(\"Test accs:\", testaccs)\n","    print()\n","    print(\"Mean Dev Acc.: %.2f (%.2f)\" % (np.mean(devaccs), np.std(devaccs)))\n","    print(\"Mean Test Acc.: %.2f (%.2f)\" % (np.mean(testaccs), np.std(testaccs)))\n","    print(\"\\nExec time: %.2f s. ( %d per run )\" % (total_exec_time, total_exec_time / n_runs))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
